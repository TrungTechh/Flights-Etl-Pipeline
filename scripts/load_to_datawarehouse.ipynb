{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import col, substring, year, month, dayofmonth, max, date_format, to_date, trim, udf, \\\n",
    "                            split, from_unixtime, expr, when, array\n",
    "from pyspark.sql.types import IntegerType, ArrayType, TimestampType\n",
    "\n",
    "from py4j.java_gateway import java_import\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "df = spark.read.parquet('/datalake/bronze/flights')\n",
    "\n",
    "df = df.withColumn(\"searchDate\", to_date(col(\"searchDate\"), \"yyyy-MM-dd\")) \\\n",
    "        .withColumn(\"flightDate\", to_date(col(\"flightDate\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "df = df.withColumn(\"startingAirport\", trim(col(\"startingAirport\"))) \\\n",
    "        .withColumn(\"destinationAirport\", trim(col(\"destinationAirport\"))) \\\n",
    "        .withColumn(\"fareBasisCode\", trim(col(\"fareBasisCode\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert travelDuration to total of minutes\n",
    "def duration_to_minutes(duration):\n",
    "    match = re.match(r'PT(\\d+H)?(\\d+M)?', duration)\n",
    "    if not match:\n",
    "        return None\n",
    "    hours = int(match.group(1)[:-1]) if match.group(1) else 0\n",
    "    minutes = int(match.group(2)[:-1]) if match.group(2) else 0\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "# Register the function as a UDF\n",
    "duration_to_minutes_udf = udf(duration_to_minutes, IntegerType())\n",
    "\n",
    "# Convert travelDuration to total minutes\n",
    "df = df.withColumn(\"travelDuration\", duration_to_minutes_udf(df[\"travelDuration\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out rows where baseFare is greater than totalFare\n",
    "df= df.filter(df[\"baseFare\"] <= df[\"totalFare\"])\n",
    "\n",
    "#filter out rows where baseFare is greater than totalFare\n",
    "df= df.filter(df[\"seatsRemaining\"] >= 0)\n",
    "\n",
    "def split_to_array(df,new_column, old_column):\n",
    "    new_df = df.withColumn(new_column, \n",
    "                   when(df[old_column].isNull(), array())\n",
    "                   .otherwise(split(col(old_column), r'\\|\\|')))\n",
    "    return new_df\n",
    "\n",
    "# Define a UDF to convert ISO 8601 string to timestamp\n",
    "def iso_to_timestamp(iso_string):\n",
    "    from datetime import datetime\n",
    "    return datetime.fromisoformat(iso_string.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "# Split the column into an array of strings\n",
    "df = split_to_array(df, \"arrivalTimeArray\", \"segmentsArrivalTimeRaw\")\n",
    "df = split_to_array(df, \"departureTimeArray\", \"segmentsDepartureTimeRaw\")\n",
    "\n",
    "iso_to_timestamp_udf = udf(iso_to_timestamp, TimestampType())\n",
    "\n",
    "# Apply the UDF to convert each element of the array to a timestamp\n",
    "df = df.withColumn(\"arrivalTimeArray\", expr(\"transform(arrivalTimeArray, x -> timestamp(x))\"))\n",
    "df = df.withColumn(\"departureTimeArray\", expr(\"transform(departureTimeArray, x -> timestamp(x))\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array in arrival airport ,airline and description\n",
    "df = split_to_array(df, \"arrivalAirportArray\", \"segmentsArrivalAirportCode\")\n",
    "df = split_to_array(df, \"departureAirportArray\", \"segmentsDepartureAirportCode\")\n",
    "\n",
    "df = split_to_array(df, \"airlineCodeArray\", \"segmentsAirlineCode\")\n",
    "df = split_to_array(df, \"airlineNameArray\", \"segmentsAirlineName\")\n",
    "\n",
    "df = split_to_array(df, \"equipDescriptionArray\", \"segmentsEquipmentDescription\")\n",
    "\n",
    "df = split_to_array(df, \"CabinCodeArray\", \"segmentsCabinCode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_and_convert_udf = \\\n",
    "    expr(\"transform(durationSecondsArray, x -> if(x is null or trim(x) in ('None', 'null'), 0, cast(x as int)))\")\n",
    "\n",
    "df = split_to_array(df, \"durationSecondsArray\", \"segmentsDurationInSeconds\")\n",
    "df = df.withColumn(\"durationSecondsArray\", replace_and_convert_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_and_convert_udf = \\\n",
    "    expr(\"transform(distanceArray, x -> if(x is null or trim(x) in ('None', 'null'), 0, cast(x as int)))\")\n",
    "df = split_to_array(df, \"distanceArray\", \"segmentsDistance\")\n",
    "df = df.withColumn(\"distanceArray\", replace_and_convert_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop segment columns\n",
    "segment_columns = [col_name for col_name in df.columns if col_name.startswith(\"segment\")]\n",
    "df = df.drop(*segment_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "chunk_size = 1000000\n",
    "min_index = df.agg(min('index')).collect()[0][0]\n",
    "max_index = min_index + chunk_size\n",
    "\n",
    "tblQuery = f\"SELECT * \\\n",
    "            FROM fligths \\\n",
    "            WHERE index BETWEEN {min_index-1} AND {max_index}\"\n",
    "df.createOrReplaceTempView(\"fligths\")\n",
    "\n",
    "while True:\n",
    "    start = time.time()\n",
    "    output_df = spark.sql(tblQuery)\n",
    "\n",
    "    if df.rdd.isEmpty():\n",
    "        break\n",
    "\n",
    "    #write data to datalake\n",
    "    output_df.write.partitionBy(\"year\",\"month\",\"day\").mode(\"append\").parquet(\"/datalake/silver/flights\")\n",
    "    print(\"It tooks \" + str(time.time() - start) +\" seconds to insert another chunks\")\n",
    "\n",
    "    min_index = max_index + 1\n",
    "    max_index = max_index + chunk_size"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
